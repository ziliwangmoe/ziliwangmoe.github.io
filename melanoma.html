<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link rel="stylesheet" type="text/css" href="css/mystyle.css" />
</head>
<body>
<h1>Auto-recognition of Melanoma (Skin Cancer) based on Cell Phone Camera</h1>
<h2 class="subTitle">Background</h2>
<p>Melanoma is the most dead skin cancer. The resource to detect melanoma is expensive and limited. There are differences between image of lesion of melanoma and other non-deadly skin lesion. It is possible to tell whether it is melanoma based on image of lesion. Even the pattern recognition technique can be applied to the recognition of melanoma, so melanoma can be automatically recognized, but the images used in recognition must be generated by specific professional equipment. So, can the recognition be pushed to the limited that use normal images like images generated by smart-phone camera in recognition? This is meaningful, because by doing so the recognition work can be done at home, everyone can do it almost free. We do not need extreme accuracy in the self-detection of melanoma, because it is only used for the preliminary examination.</p>
<img src="img/mela/b5.jpg" style="width:400px"/>
<p class="figDesc">Fig.1 Image of melanoma</p>
<img src="img/mela/g1.jpg" style="width:400px"/>
<p class="figDesc">Fig.2 Image of benign skin cancer</p>

<h2 class="subTitle">Highlights</h2>
<li>1. Used images obtaining from online.</li>
<li>2. Five features were abstracted from each image.</li>
<li>3. SVM was used to classify the images based on the 5 features.</li>
<li>4. Cross-validation was used to further optimise the method.</li>

<h2 class="subTitle">Details</h2>
<h3>Database:</h3>
<p>I find 30 and 14 images of non-melanoma and melanoma respectively online, and some image processing works are applied to the images.</p>

<h3>Five Features needed to be extracted from images:</h3>
<h4>1, Degree of asymmetry of shape.</h4>
<img src="img/mela/ss.jpg" />
<p class="figDesc">Fig.3 Image of a melanoma after segment. The white area denotes the pattern of melanoma.</p>
<img src="img/mela/aa.jpg" />
<p class="figDesc">Fig.4 Image of a melanoma after KL transform, pattern is align to main axis.</p>
<img src="img/mela/shapeAsy.jpg" />
<p class="figDesc">Fig.5 Distribution of degree of asymmetry of shape<br>
<span style="color:red">Red line: melanoma</span><br>
<span style="color:blue">Blue line: non-melanoma</span></p>

<h4>2, Degree of asymmetry of color distribution.</h4>
<p>First I applied KL transform to align the pattern to main axis. Then measured the axial symmetry of illumination distribution inside the melanoma. </p>
<img src="img/mela/colorasy.jpg" />
<p class="figDesc">Fig.6 Distribution of degree of asymmetry of color distribution<br>
<span style="color:red">Red line: melanoma</span><br>
<span style="color:blue">Blue line: non-melanomaa</span></p>
<h4>3, Degree of variance of color</h4>
<p>Computer the variance of R,G,B, and average the three numbers to get the degree of variance of color.</p>
<img src="img/mela/colorvar.jpg" />
<p class="figDesc">Fig.7 Distribution of degree of variance of color<br>
<span style="color:red">Red line: melanoma</span><br>
<span style="color:blue">Blue line: non-melanoma</span></p>
<h4>4, Degree of lump of border.</h4>
<p>I use the fractal dimension to indicate the degree of lump of border. But because the border curve of pattern is not a real fractal shape, I canâ€™t obtain the real dimension. In fact the fractal dimension of our pattern depends on the size of unit we use to measure. So I must choose a proper size of unit with which the melanoma can be detected most effectively.</p>
<img src="img/mela/border.jpg" />
<p class="figDesc">Fig.8 Distribution of degree of lump of border<br>
<span style="color:red">Red line: melanoma</span><br>
<span style="color:blue">Blue line: non-melanoma</span></p>
<h4>5, Distance between colors represented in RGB space.</h4>
<p>First I computed the mean R,G,B components of melanoma and non-melanoma, and obtained two points in RGB space which represented melanoma and non-melanoma respectively: (Rgood,Ggood,Bgood) and (Rbad,Gbad,Bbad). Then I computed the distance in RGB space between the color of each sample image to point (Rgood,Ggood,Bgood).</p>
<img src="img/mela/abscolor.jpg" />
<p class="figDesc">Fig.9 Distribution of Distance in RGB space<br>
<span style="color:red">Red line: melanoma</span><br>
<span style="color:blue">Blue line: non-melanoma</span></p>
<img src="img/mela/orc.jpg" />
<p class="figDesc">Fig.10 ROC of each feature. Rose, green, black, blue and red color curve represent feature 3, 1, 2, 4, 5</p>

<h3>Applying SVM:</h3>
<p>I implemented the SVM by myself based on the matlab build-in Quadratic programming solver. I used the Polynomial Kernel function with the parameter equate to 2. And chose a proper value for the slack variable. Before fed the features into SVM, I normalized the data by dividing the norm of the feature vector.</p>
<img src="img/mela/linear.jpg" /></br>
<img src="img/mela/qua.jpg" />
<p class="figDesc">Fig.11 Margin of classification. Horizontal axis and vertical axis denote feature 1 and feature 3 respectively<br>
<span style="color:red">Red point: melanoma</span><br>
<span style="color:blue">Blue point: non-melanoma</span></p>

<h3>Cross-validation:</h3>
I had 30 images of non-melanoma and 14 images of melanoma. I divided them into two groups, each group had 15 images of non-melanoma and 7 images of melanoma. <br>
First I used the first group as training sample, and computed the accuracy rate by using the second group, and then used the second group as training sample and computed accuracy rate by using the first group.  <br>
Then I used the mean value of these two accuracy rate as the accuracy rate of classifier. According to the accuracy rate I could choose a proper slack variable.</p>
<p>
<table>
<tr><td>Feature</td><td>2</td><td>3</td><td>4</td><td>5</td></tr>
<tr><td>1</td><td>0.84</td><td>0.73</td><td>0.86</td><td>0.84</td></tr>
<tr><td>2</td><td></td><td>0.86</td><td>0.84</td><td>0.84</td></tr>
<tr><td>3</td><td></td><td></td><td>0.79</td><td>0.84</td></tr>
<tr><td>4</td><td></td><td></td><td></td><td>0.91</td></tr>
</table>
<p class="figDesc">Table.1 Accuracy rate by using <b>two</b> features, the meaning of number in the table are described as below:<br>
1: Distance between colors in RGB space.<br>
2: Degree of lump of border.<br>
3: Degree of asymmetry of color distribution.<br>
4: Degree of variance of color.<br>
5: Degree of asymmetry of shape.<br>
We can find the highest rate occur when using feature 4 and 5</p>
</p>

<table>
<tr><td>feature</td><td>4&5</td></tr>
<tr><td>1</td><td>0.88</td></tr>
<tr><td>2</td><td>0.91</td></tr>
<tr><td>3</td><td>0.91</td></tr>
</table>
<p class="figDesc">Accuracy rate by using <b>three</b> features, the meaning of number in the table are same as Table.1<br>
We can find the highest rate occur when using feature 4 and 5</p>
<p>Further study show that the accurate rate is not enhanced by adding more features compare to just using feature 4 and feature 5.</p>

<h2 class="subTitle">Conclusion</h2>
From the analysis, we found that using degree of variance of color and degree of asymmetry of shape as the indicators to recognize melanoma can get the best effect. The quantitative result was good, but there were many obvious deficiencies in the process, so there is still a lot of work to do until the idea become a feasible industry application. 
</body>
</html>